# Описание пайплайна

Пайплайн предназначен для переноса событий пользователей из PostgreSQL в ClickHouse через промежуточный слой Kafka. Система обеспечивает защиту от дублирования данных с помощью флага sent_to_kafka. Пайплайн включает следующие компоненты:

1. **Сбор данных**: Пайплайн генерирует события входа для случайных пользователей.
2. **Отправка данных в Kafka**: События отправляются в топик `user_events`.
3. **Сохранение данных**: Информация о каждом событии сохраняется в таблице `user_logins` в базе данных.

## Компоненты системы

- PostgreSQL - источник данных
- Kafka - брокер сообщений
- ClickHouse - целевое хранилище
- Producer - скрипт для чтения из PostgreSQL и записи в Kafka
- Consumer - скрипт для чтения из Kafka и записи в ClickHouse.

## Подготовка
В DBeaver добавить столбец sent_to_kafka в таблицу user_logins
```
ALTER TABLE user_logins ADD COLUMN sent_to_kafka BOOLEAN DEFAULT FALSE;
```
## Конфигурация

Основные параметры конфигурации находятся в файлах:
- В producer.py:
  Настройки подключения к PostgreSQL
  Настройки Kafka
- В consumer.py:
  Настройки Kafka
  Настройки ClickHouse

# Запуск
- Запусr продюсера:
```
python producer.py
```
В процессе выполнения в консоли будет отображаться информация о отправленных данных:

```
Sent: {'user': 'dave', 'event': 'login', 'timestamp': 1751815424.426091}
```
- Запусr консьюмера:
```
python consumer_to_clickhouse.py
```
После запуска скрипт начнет слушать сообщения из топика user_events и вставлять их в таблицу user_logins
```
Received: {'user': 'carol', 'event': 'login', 'timestamp': 1751815418.417686}
```

## Завершение работы

Чтобы остановить выполнение пайплайна, нужно нажать `Ctrl + C` в терминале.

